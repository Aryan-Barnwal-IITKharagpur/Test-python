# -*- coding: utf-8 -*-
"""Untitled8.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BGLPQ89OyK01YTy3AnRZga1uLegpFtCi
"""

# ---------------------------------------------------------
# Diabetes 130-US Hospitals Dataset - Full Preprocessing + ML
# ---------------------------------------------------------

# ------------------- Libraries ---------------------------
# pandas: for handling data tables (rows & columns)
import pandas as pd

# numpy: numerical computing, math operations, arrays
import numpy as np

# matplotlib & seaborn: for plotting charts and visualizations
import matplotlib.pyplot as plt
import seaborn as sns

# scikit-learn tools:
# - train_test_split: split data into training and testing sets
# - OneHotEncoder: convert categorical columns to numeric (0/1)
# - StandardScaler: scale numeric features to same range
# - SimpleImputer: fill missing values in numeric or categorical columns
# - Pipeline: combine multiple steps into one sequence
# - ColumnTransformer: apply different preprocessing to numeric & categorical columns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer

# scikit-learn classifiers:
# LogisticRegression: simple linear model for binary classification
# RandomForestClassifier: ensemble of decision trees
# GradientBoostingClassifier: boosting method that builds trees sequentially
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier

# scikit-learn metrics:
# classification_report: precision, recall, F1-score
# confusion_matrix: table showing true positives, false positives, etc.
# roc_auc_score: overall ranking performance
# roc_curve: data for plotting ROC curve
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve

# ------------------- 1. Load Dataset -------------------
# Read CSV file into pandas DataFrame
df = pd.read_csv("diabetic_data.csv")  # df is now a table with rows=patients, columns=features

# ------------------- 2. Define Target -------------------
# The original 'readmitted' column has three values: '<30', '>30', 'NO'
# We create a binary target:
#   1 = patient readmitted within 30 days ('<30')
#   0 = otherwise ('>30' or 'NO')
df['readmitted'] = df['readmitted'].apply(lambda x: 1 if x == '<30' else 0)

# ------------------- 3. Drop Useless Columns -------------------
# 'encounter_id' and 'patient_nbr' are identifiers
# They do not contain useful predictive information
df = df.drop(["encounter_id", "patient_nbr"], axis=1)

# ------------------- 4. Split Features -------------------
# Identify numeric and categorical columns separately
numeric_features = df.select_dtypes(include=["int64", "float64"]).columns
categorical_features = df.select_dtypes(include=["object"]).columns

# ------------------- 5. Preprocessing Pipelines -------------------

# Numeric pipeline:
# Step 1: fill missing numbers with median (robust to outliers)
# Step 2: scale features to have mean=0 and std=1
numeric_transformer = Pipeline(steps=[
    ("imputer", SimpleImputer(strategy="median")),
    ("scaler", StandardScaler())
])

# Categorical pipeline:
# Step 1: fill missing categories with most frequent value
# Step 2: convert categories to numbers using one-hot encoding
# handle_unknown='ignore' ensures unseen categories in test set don't crash the model
categorical_transformer = Pipeline(steps=[
    ("imputer", SimpleImputer(strategy="most_frequent")),
    ("encoder", OneHotEncoder(handle_unknown="ignore"))
])

# Combine numeric & categorical preprocessing
# ColumnTransformer applies numeric_transformer to numeric columns
# and categorical_transformer to categorical columns
preprocessor = ColumnTransformer(
    transformers=[
        ("num", numeric_transformer, numeric_features),
        ("cat", categorical_transformer, categorical_features)
    ]
)

# ------------------- 6. Train-Test Split -------------------
# X = all features (drop target column)
# y = target column (0/1 for readmission within 30 days)
X = df.drop("readmitted", axis=1)
y = df["readmitted"]

# Split into 80% training and 20% testing
# stratify=y ensures same proportion of positive/negative classes in both sets
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

# ------------------- 7. Define Models -------------------
# We use three models for comparison
models = {
    "Logistic Regression": LogisticRegression(max_iter=1000, class_weight="balanced"),
    "Random Forest": RandomForestClassifier(n_estimators=100, class_weight="balanced", random_state=42),
    "Gradient Boosting": GradientBoostingClassifier(n_estimators=100, random_state=42)
}

# ------------------- 8. Train, Evaluate, Visualize -------------------
for name, model in models.items():
    # Combine preprocessing + model into one pipeline
    clf = Pipeline(steps=[("preprocessor", preprocessor),
                          ("classifier", model)])

    # Train pipeline on training data
    clf.fit(X_train, y_train)

    # Predict class labels on test data
    y_pred = clf.predict(X_test)

    # Predict probabilities for positive class (used for ROC AUC)
    y_proba = clf.predict_proba(X_test)[:, 1]

    # Print classification report: precision, recall, F1-score
    print(f"--- {name} ---")
    print(classification_report(y_test, y_pred))

    # Calculate ROC-AUC score
    auc = roc_auc_score(y_test, y_proba)
    print(f"ROC AUC: {auc:.3f}")

    # Compute confusion matrix
    cm = confusion_matrix(y_test, y_pred)

    # Plot confusion matrix as heatmap
    plt.figure(figsize=(4, 3))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")
    plt.title(f"{name} - Confusion Matrix")
    plt.xlabel("Predicted")
    plt.ylabel("Actual")
    plt.show()

    # Plot ROC curve
    fpr, tpr, thresholds = roc_curve(y_test, y_proba)
    plt.figure()
    plt.plot(fpr, tpr, label=f"{name} (AUC = {auc:.3f})")
    plt.plot([0,1], [0,1], 'k--')  # random guessing line
    plt.xlabel("False Positive Rate")
    plt.ylabel("True Positive Rate")
    plt.title(f"{name} - ROC Curve")
    plt.legend()
    plt.show()