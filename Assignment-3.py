# -*- coding: utf-8 -*-
"""Untitled13.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KBFjUCTQDI9P8g6h1HtFNTBmdKtgB0KH
"""

import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras import layers, models

# Load MNIST
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()

# Use only 1000 samples
x_train, y_train = x_train[:1000], y_train[:1000]

# Normalize & flatten
x_train = x_train.reshape(1000, 784).astype("float32") / 255.0
x_test = x_test.reshape(-1, 784).astype("float32") / 255.0

# Build model
model = models.Sequential([
    layers.Dense(128, activation="relu", input_shape=(784,)),
    layers.Dense(64, activation="relu"),
    layers.Dense(10, activation="softmax")
])

model.compile(optimizer="adam",
              loss="sparse_categorical_crossentropy",
              metrics=["accuracy"])

# Train & record history
history = model.fit(
    x_train, y_train,
    epochs=10, batch_size=32,
    validation_data=(x_test, y_test),
    verbose=0
)

# Plot accuracy
plt.figure(figsize=(12,6))
plt.subplot(1,2,1)
plt.plot(history.history['accuracy'], label='Train Acc')
plt.plot(history.history['val_accuracy'], label='Test Acc')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Accuracy per Epoch')
plt.legend()


# Plot loss
plt.subplot(1,2,2)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Test Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Loss per Epoch')
plt.legend()

plt.tight_layout()
plt.show()

# Pick 10 random test images
indices = random.sample(range(len(x_test)), 10)
images = x_test[indices]
labels = y_test[indices]

# Predict
preds = model.predict(x_test_flat[indices])

# Plot
plt.figure(figsize=(12, 4))
for i in range(10):
    plt.subplot(2, 5, i+1)
    plt.imshow(images[i].reshape(28, 28), cmap="gray")   # ðŸ”¹ reshape added
    plt.title(f"True: {labels[i]}\nPred: {np.argmax(preds[i])}")
    plt.axis("off")
plt.tight_layout()
plt.show()

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import Subset, DataLoader
import matplotlib.pyplot as plt
import random

# Load MNIST
transform = transforms.Compose([transforms.ToTensor(), transforms.Lambda(lambda x: x.view(-1))])

train_dataset = datasets.MNIST(root="./data", train=True, transform=transform, download=True)
test_dataset = datasets.MNIST(root="./data", train=False, transform=transform)

# Subset (1000 samples only for training)
train_subset = Subset(train_dataset, range(1000))
train_loader = DataLoader(train_subset, batch_size=32, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

# Model
class FeedForwardNN(nn.Module):
    def __init__(self):
        super().__init__()
        self.fc1 = nn.Linear(784, 128)
        self.fc2 = nn.Linear(128, 64)
        self.fc3 = nn.Linear(64, 10)
    def forward(self, x):
        x = torch.relu(self.fc1(x))
        x = torch.relu(self.fc2(x))
        return self.fc3(x)

model = FeedForwardNN()
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

train_acc, test_acc = [], []
train_loss, test_loss = [], []

# Training loop
for epoch in range(10):
    correct, total, running_loss = 0, 0, 0.0
    model.train()
    for data, target in train_loader:
        optimizer.zero_grad()
        outputs = model(data)
        loss = criterion(outputs, target)
        loss.backward()
        optimizer.step()
        running_loss += loss.item()
        _, predicted = torch.max(outputs, 1)
        total += target.size(0)
        correct += (predicted == target).sum().item()
    train_acc.append(correct / total)
    train_loss.append(running_loss / len(train_loader))

    # Test
    correct, total, running_loss = 0, 0, 0.0
    model.eval()
    with torch.no_grad():
        for data, target in test_loader:
            outputs = model(data)
            loss = criterion(outputs, target)
            running_loss += loss.item()
            _, predicted = torch.max(outputs, 1)
            total += target.size(0)
            correct += (predicted == target).sum().item()
    test_acc.append(correct / total)
    test_loss.append(running_loss / len(test_loader))

# Plot accuracy
plt.figure(figsize=(12,5))
plt.subplot(1,2,1)
plt.plot(train_acc, label="Train Acc (PyTorch)")
plt.plot(test_acc, label="Test Acc (PyTorch)")
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.title("Accuracy per Epoch")
plt.legend()

# Plot loss
plt.subplot(1,2,2)
plt.plot(train_loss, label="Train Loss")
plt.plot(test_loss, label="Test Loss")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.title("Loss per Epoch")
plt.legend()

plt.tight_layout()
plt.show()

import random
import numpy as np

# Pick 10 random test images from the PyTorch dataset
indices = random.sample(range(len(test_dataset)), 10)
images, labels = zip(*[test_dataset[i] for i in indices])

# Stack into a tensor
images_tensor = torch.stack(images)

# Predict
model.eval()
with torch.no_grad():
    outputs = model(images_tensor)
    preds = torch.argmax(outputs, 1)

# Plot
plt.figure(figsize=(12, 4))
for i in range(10):
    plt.subplot(2, 5, i+1)
    plt.imshow(images[i].view(28, 28), cmap="gray")   # un-flatten
    plt.title(f"True: {labels[i]}\nPred: {preds[i].item()}")
    plt.axis("off")
plt.tight_layout()
plt.show()

Step 1: Dataset Preparation

I started with the MNIST dataset, which has grayscale handwritten digit images of size 28Ã—28. Each image is flattened into a 784-dimensional vector using a transform so that it can go directly into a fully connected network.
I then created a subset of the first 1000 training images for faster training and kept the entire test dataset for evaluation.

Step 2: Model Architecture

The model is a simple feedforward neural network with three layers:

Input layer: 784 neurons (flattened pixels).

Hidden layers: 128 neurons and 64 neurons, both with ReLU activation.

Output layer: 10 neurons (corresponding to digits 0â€“9).

This is a pretty classic MLP (multi-layer perceptron) setup for MNIST.

Step 3: Training Setup

For the training:

Loss function: CrossEntropyLoss, since itâ€™s a multi-class classification problem.

Optimizer: Adam with learning rate 0.001.

I trained the model for 10 epochs. For each epoch, I measured two things:

Accuracy (how many digits it predicts correctly).

Loss (a measure of how far predictions are from correct answers).

Step 4: Results & Visualization

At the end of training, I plotted both accuracy and loss curves:

Accuracy plot: Shows how the training accuracy improves steadily, and the test accuracy also improves, but it usually saturates earlier because weâ€™re training on just 1,000 samples.

Loss plot: Training loss decreases nicely across epochs, showing the model is learning. Test loss may fluctuate a bit, which reflects generalization challenges with such a small training set.

This dual plot is helpful: accuracy tells us performance in percentage terms, while loss gives a finer view of how well the optimization is progressing.

Step 5: Insights

With only 1,000 samples, the model still manages to learn reasonably well, which shows the power of even a small feedforward network.

However, compared to using the full dataset, performance is limited â€” we might see test accuracy stall around 85â€“90% instead of going above 97%.

This exercise also highlights how PyTorch gives us granular control over training loops, allowing us to manually record loss, accuracy, and visualize them clearly.

ðŸŽ¯ Conclusion

In summary, this code demonstrates the end-to-end process of training a neural network on MNIST in PyTorch, monitoring both accuracy and loss, and visualizing results. Itâ€™s a compact but very educational example because we see how performance evolves with limited data, and we get both quantitative (accuracy/loss numbers) and qualitative (plots) insights into training.